{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Some organisations have already built applications that work with OpenAI compatible API and would like to switch to Amazon Bedrock -- this guide is to help you achieve that without changing app code by using LiteLLM.</p>"},{"location":"10-architecture/10-architecture/","title":"Architecture","text":"<p>The diagram below depicts the solution architecture. LiteLLM is used as a proxy to translate the API call originating from the app in OpenAI format to Bedrock format.</p> <p></p> <p>LiteLLM is deployed on Amazon EKS. If the app is hosted on the same cluster, it can access LiteLLM internally through Kubernetes <code>Service</code> of <code>type</code> <code>ClusterIP</code>. If the app is hosted outside the cluster, LiteLLM has to be exposed via a load balancer -- refer to Exposing applications section of Amazon EKS workshop for guidance. This implementation assumes the app is hosted on the same cluster.</p> <p>While LiteLLM is only used as a proxy in this implementation, it has several other features e.g. retry/fallback logic across multiple deployments, track spend &amp; set budgets per project, etc.</p>"},{"location":"20-deploy/10-prerequisites/","title":"Prerequisites","text":"<p>If you will use Open WebUI to test LiteLLM configurations, the following prerequisites apply:</p> <ul> <li>A domain that can be used for hosting Open WebUI, a web frontend that allows users to interact with LLMs; it will be used to test LiteLLM setup.</li> <li>A digital certificate in AWS Certificate Manager (ACM) for enabling TLS on Open WebUI</li> </ul> <p>If you will expose LiteLLM outside the EKS cluster, the following prerequisites apply:</p> <ul> <li>A domain that can be used for hosting LiteLLM and exposing it externally through public endpoint.</li> <li>A digital certificate in AWS Certificate Manager (ACM) for enabling TLS on LiteLLM</li> </ul>"},{"location":"20-deploy/20-configure-env-variables/","title":"Configure environment variables","text":"<p>Note</p> <p>The steps in the following sections have been tested on Cloud9/Amazon Linux. Make sure to disable AWS managed temporary credentials and attach an IAM role with sufficient permissions.</p> <ol> <li>Configure environment variables</li> </ol> <pre><code>export TOKEN=`curl -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\"`\nexport AWS_REGION=`curl -H \"X-aws-ec2-metadata-token: $TOKEN\" http://169.254.169.254/latest/meta-data/placement/region`\nexport CLUSTER_NAME=\"litellm-demo\"\n\necho \"export AWS_REGION=${AWS_REGION}\" | tee -a ~/.bash_profile\necho \"export CLUSTER_NAME=${CLUSTER_NAME}\" | tee -a ~/.bash_profile\n</code></pre>"},{"location":"20-deploy/25-clone-repo/","title":"Clone the repo","text":"<ol> <li>Clone bedrock-litellm repo <pre><code>git clone https://github.com/aws-samples/bedrock-litellm.git\n</code></pre></li> <li>Save bedrock-litellm directory in an environment variable <pre><code>export BEDROCK_LITELLM_DIR=$PWD/bedrock-litellm\necho \"export BEDROCK_LITELLM_DIR=${BEDROCK_LITELLM_DIR}\" | tee -a ~/.bash_profile\n</code></pre></li> </ol>"},{"location":"20-deploy/30-tools/","title":"Install Kubernetes tools","text":"<ol> <li> <p>Install eksctl: <pre><code># for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`\nARCH=amd64\nPLATFORM=$(uname -s)_$ARCH\n\ncurl -sLO \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz\"\n\n# (Optional) Verify checksum\ncurl -sL \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\" | grep $PLATFORM | sha256sum --check\n\ntar -xzf eksctl_$PLATFORM.tar.gz -C /tmp &amp;&amp; rm eksctl_$PLATFORM.tar.gz\n\nsudo mv /tmp/eksctl /usr/local/bin\n</code></pre></p> </li> <li> <p>Install kubectl: <pre><code>curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.30.0/2024-05-12/bin/linux/amd64/kubectl\nchmod +x ./kubectl\nmkdir -p $HOME/bin &amp;&amp; cp ./kubectl $HOME/bin/kubectl &amp;&amp; export PATH=$HOME/bin:$PATH\n</code></pre></p> </li> <li> <p>Install yq: <pre><code>echo 'yq() {\n  docker run --rm -i -v \"${PWD}\":/workdir mikefarah/yq \"$@\"\n}' | tee -a ~/.bashrc &amp;&amp; source ~/.bashrc\n</code></pre></p> </li> <li> <p>Install Helm: <pre><code>curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nchmod 700 get_helm.sh\n./get_helm.sh\n</code></pre></p> </li> <li> <p>Install envsubst: <pre><code>curl -L https://github.com/a8m/envsubst/releases/download/v1.2.0/envsubst-`uname -s`-`uname -m` -o envsubst\nchmod +x envsubst\nsudo mv envsubst /usr/local/bin\n</code></pre></p> </li> </ol>"},{"location":"20-deploy/40-create-prepare-cluster/","title":"Create and prepare an EKS cluster","text":"<ol> <li> <p>Create cluster: <pre><code>envsubst &lt; $BEDROCK_LITELLM_DIR/eksctl/cluster-config.yaml | eksctl create cluster -f -\n</code></pre></p> </li> <li> <p>Create an IAM OIDC provider for the cluster to be able to use IAM roles for service accounts (required for granting IAM permissions to LiteLLM to be able to invoke Bedrock models): <pre><code>eksctl utils associate-iam-oidc-provider --cluster $CLUSTER_NAME --approve\n</code></pre></p> </li> <li> <p>(Optional) Install AWS Load Balancer Controller (AWS LBC):</p> <p>Note</p> <p>Install AWS Load Balancer Controller if you are planning to expose LiteLLM or one of the clients on ELB.</p> <p>First, create the IAM policy:</p> <pre><code>curl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.7.2/docs/install/iam_policy.json\n\nexport AWS_LBC_IAM_POLICY_ARN=$(aws iam create-policy \\\n--policy-name AWSLoadBalancerControllerIAMPolicy \\\n--policy-document file://iam_policy.json \\\n--output text \\\n--query \"Policy.Arn\")\necho \"export AWS_LBC_IAM_POLICY_ARN=${AWS_LBC_IAM_POLICY_ARN}\" | tee -a ~/.bash_profile\n</code></pre> <p>Then, create IRSA setup: <pre><code>eksctl create iamserviceaccount \\\n    --cluster $CLUSTER_NAME \\\n    --namespace=kube-system \\\n    --name=aws-load-balancer-controller \\\n    --role-name AmazonEKS_LoadBalancerController_Role \\\n    --attach-policy-arn $AWS_LBC_IAM_POLICY_ARN \\\n    --approve\n</code></pre> Then, install AWS LBC helm chart: <pre><code>helm repo add eks https://aws.github.io/eks-charts\nhelm repo update eks\nhelm install aws-load-balancer-controller eks/aws-load-balancer-controller \\\n--namespace kube-system \\\n--set clusterName=$CLUSTER_NAME \\\n--set serviceAccount.create=false \\\n--set serviceAccount.name=aws-load-balancer-controller \n</code></pre></p> </li> <li> <p>(Optional) Install EBS CSI driver (EBS volumes will be used to store Open WebUI state):</p> <p>Note</p> <p>Install EBS CSI driver if you are planning to use Open WebUI as it depends on EBS volumes for storing its state.</p> <p>First, create IRSA dependencies: <pre><code>eksctl create iamserviceaccount \\\n    --name ebs-csi-controller-sa \\\n    --namespace kube-system \\\n    --cluster $CLUSTER_NAME \\\n    --role-name AmazonEKS_EBS_CSI_DriverRole \\\n    --attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \\\n    --approve\n</code></pre> Then, install EBS CSI driver helm chart: <pre><code>helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver\nhelm repo update\nhelm upgrade --install aws-ebs-csi-driver \\\n    --namespace kube-system \\\n    --set controller.serviceAccount.create=false \\\n    aws-ebs-csi-driver/aws-ebs-csi-driver\n</code></pre></p> </li> </ol>"},{"location":"20-deploy/50-install-litellm/","title":"Install LiteLLM","text":"<ol> <li> <p>Clone LiteLLM repo <pre><code>git clone https://github.com/BerriAI/litellm.git\n</code></pre></p> </li> <li> <p>Save LiteLLM directory in an environment variable <pre><code>export LITELLM_DIR=$PWD/litellm\necho \"export LITELLM_DIR=${LITELLM_DIR}\" | tee -a ~/.bash_profile\n</code></pre></p> </li> <li> <p>Create IRSA dependencies for LiteLLM</p> <p>First, create IAM policy: <pre><code>sed -i \"s/AWS_REGION/$AWS_REGION/g\" $BEDROCK_LITELLM_DIR/iam/litellm-bedrock-policy.json\nexport LITELLM_BEDROCK_IAM_POLICY_ARN=$(aws iam create-policy \\\n--policy-name litellm-bedrock-policy \\\n--policy-document file://$BEDROCK_LITELLM_DIR/iam/litellm-bedrock-policy.json \\\n--output text \\\n--query \"Policy.Arn\")\necho \"export LITELLM_BEDROCK_IAM_POLICY_ARN=${LITELLM_BEDROCK_IAM_POLICY_ARN}\" | tee -a ~/.bash_profile\n</code></pre></p> <p>Then, create IRSA setup: <pre><code>eksctl create iamserviceaccount \\\n    --name litellm-sa \\\n    --cluster $CLUSTER_NAME \\\n    --role-name AmazonEKS_LiteLLM_Role \\\n    --attach-policy-arn $LITELLM_BEDROCK_IAM_POLICY_ARN \\\n    --approve\n</code></pre></p> </li> <li> <p>Install LiteLLM</p> <p>Note</p> <p>LiteLLM helm chart is currently BETA, hence K8s manifests were used for installation. The snippet below will be changed once the helm chart is GAed.</p> <pre><code>yq -i '.spec.template.spec.serviceAccount= \"litellm-sa\"' litellm/deploy/kubernetes/kub.yaml\nyq -i 'del(.spec.template.spec.containers[0].env[] | select(.name == \"DATABASE_URL\") )' litellm/deploy/kubernetes/kub.yaml\nyq -i '.spec.type= \"ClusterIP\"' litellm/deploy/kubernetes/service.yaml\n\nkubectl create configmap litellm-config --from-file=$BEDROCK_LITELLM_DIR/litellm/proxy_config.yaml\nkubectl apply -f $LITELLM_DIR/deploy/kubernetes/kub.yaml\nkubectl apply -f $LITELLM_DIR/deploy/kubernetes/service.yaml\n</code></pre> </li> <li> <p>Allow acess to Bedrock models by following the steps in this doc page.</p> </li> <li> <p>Ensure that LiteLLM pods are up and running</p> </li> <li> <p>Verify LiteLLM</p> <pre><code>kubectl run curl --image=curlimages/curl --rm -it -- /bin/sh\ncurl --location \"http://litellm-service.default.svc.cluster.local:4000/chat/completions\" \\\n    --header 'Content-Type: application/json' \\\n    --header 'Authorization: Bearer sk-1234' \\\n    --data '{\n    \"model\": \"bedrock-llama3-8b-instruct-v1\",\n    \"messages\": [\n        {\n        \"role\": \"user\",\n        \"content\": \"what llm are you\"\n        }\n    ]\n}'\n</code></pre> </li> </ol>"},{"location":"20-deploy/60-expose-litellm/","title":"Expose LiteLLM","text":"<ol> <li> <p>Configure environment variables; replace <code>&lt;litellm-hostname&gt;</code>, <code>&lt;litellm-cert-arn&gt;</code> with the corresponding hostnames and ACM certificates ARN.     <pre><code>export LITELLM_HOSTNAME=\"&lt;litellm-hostname&gt;\"\nexport LITELLM_CERTIFICATE_ARN=\"&lt;litellm-cert-arn&gt;\"\n\necho \"export LITELLM_HOSTNAME=${LITELLM_HOSTNAME}\" | tee -a ~/.bash_profile\necho \"export LITELLM_CERTIFICATE_ARN=${LITELLM_CERTIFICATE_ARN}\" | tee -a ~/.bash_profile\n</code></pre></p> </li> <li> <p>Apply LiteLLM ingress     <pre><code>envsubst &lt; $BEDROCK_LITELLM_DIR/litellm/ingress.yaml | kubectl apply -f -\n</code></pre></p> <p>Note</p> <p>ELB needs a minutes or so to complete the target registration; if the URL above did not work for you, wait for a few seconds for the registration to get completed.</p> </li> <li> <p>Extract LiteLLM URL:     <pre><code>kubectl get ingress litellm-ingress  -o jsonpath='{.status.loadBalancer.ingress[*].hostname}'\n</code></pre></p> </li> <li> <p>Add a CNAME record for <code>&lt;litellm-hostname&gt;</code> (check prerequisities section) that points to the ALB host name, then access LiteLLM using <code>&lt;litellm-hostname&gt;</code>.</p> </li> <li> <p>Verify LiteLLM through external endpoint</p> <pre><code>curl --location \"https://${LITELLM_HOSTNAME}/chat/completions\" \\\n    --header 'Content-Type: application/json' \\\n    --header 'Authorization: Bearer sk-1234' \\\n    --data '{\n    \"model\": \"bedrock-llama3-8b-instruct-v1\",\n    \"messages\": [\n        {\n        \"role\": \"user\",\n        \"content\": \"what llm are you\"\n        }\n    ]\n}'\n</code></pre> </li> </ol>"},{"location":"30-app-changes/10-app-changes/","title":"Code Changes for OpenAI to Amazon Bedrock Migration","text":"<p>With LiteLLM successfully deployed onto Amazon EKS and proxying requests to Amazon Bedrock, you can choose to migrate from OpenAI with minimal code changes.</p> <p>Requests from your applications that do not originate from Open WebUI can be modified by updating your OpenAI base endpoint to point to your ALB DNS name. This is similar to the change we made in step 17, updating an OpenAI endpoint to point to your LiteLLM service, this time to the ALB host name, or your CNAME record for  (check prerequisities section) that points to the ALB host name. <ol> <li> <p>Update your application's OpenAI API endpoint to point to your . <pre><code>import openai\n\nopenai.api_base = {\"your-litellm-hostname\"}\nopenai.api_key = {\"your-open-ai-api-key\"}\n\n# Your existing OpenAI code remains unchanged\nresponse = openai.Completion.create(\nmodel=\"text-davinci-003\",\nprompt=\"Translate the following English text to French: 'Hello, how are you?'\"\n)\n</code></pre> <li> <p>Test and validate that your existing code and application work as expected, calling foundation models hosted on Amazon Bedrock via LiteLLM hosted on Amazon EKS. Best practices and considerations:</p> <ol> <li>Gradually migrate: Start by routing a small percentage of traffic through the LiteLLM proxy and gradually increase as you gain confidence.</li> <li>Monitor performance: Use Amazon CloudWatch to monitor the performance and AWS Cost Explorer to monitor the costs of your AWS usage, including Amazon Bedrock.</li> <li>Security: Ensure least privilege AWS Identity and Access Management (AWS IAM) roles and security groups are in place for your EKS cluster and Amazon Bedrock access.</li> <li>Scalability: Configure auto-scaling for your EKS nodes to handle varying loads.</li> </ol> </li>"},{"location":"40-clients/10-open-webui/","title":"Connect Open WebUI to LiteLLM","text":"<p>Open WebUI is a web frontend that allows users to interact with LLMs. It supports locally running LLMs using Ollama, and OpenAI-compatible remote endpoints. In this implementation, we are configuring a remote endpoint that points to LiteLLM to show how LiteLLM allows for accessing Bedrock through an OpenAI-compatible interface. </p>"},{"location":"40-clients/10-open-webui/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>An EKS cluster to host Open WebUI. This is already creeated as part of LiteLLM deployment.</li> <li>A domain that can be used for hosting Open WebUI, a web frontend that allows users to interact with LLMs; it will be used to test LiteLLM setup.</li> <li>A digital certificate in AWS Certificate Manager (ACM) for enabling TLS on Open WebUI</li> </ul>"},{"location":"40-clients/10-open-webui/#open-webui-deployment","title":"Open WebUI deployment","text":"<ol> <li> <p>Configure environment variables; replace <code>&lt;open-webui-hostname&gt;</code>, <code>&lt;open-webui-cert-arn&gt;</code> with the corresponding hostnames and ACM certificates ARN.</p> <pre><code>export OPEN_WEBUI_HOSTNAME=\"&lt;open-webui-hostname&gt;\"\nexport OPEN_WEBUI_CERTIFICATE_ARN=\"&lt;open-webui-cert-arn&gt;\"\n\necho \"export OPEN_WEBUI_HOSTNAME=${OPEN_WEBUI_HOSTNAME}\" | tee -a ~/.bash_profile\necho \"export OPEN_WEBUI_CERTIFICATE_ARN=${OPEN_WEBUI_CERTIFICATE_ARN}\" | tee -a ~/.bash_profile\n</code></pre> </li> <li> <p>Install Open WebUI:     <pre><code>helm repo add open-webui https://helm.openwebui.com/\nhelm repo update\n\nhelm upgrade \\\n    --install open-webui open-webui/open-webui \\\n    --namespace open-webui \\\n    --create-namespace \\\n    -f bedrock-litellm/helm/open-webui-private-values.yaml\n</code></pre></p> <p>The first user signing up will get admin access. So, initially, Open WebUI will be only accessible from within the cluster to securely create the first/admin user. Subsequent sign ups will be in pending state till they are approved by the admin user.</p> </li> <li> <p>Use <code>kubectl port-forward</code> to allow access to Open WebUI from the machine used for installation:     <pre><code>kubectl port-forward service/open-webui -n open-webui  8080:80\n</code></pre></p> <p>If you are using Cloud9, you can access Open WebUI by clicking \"Preview\" (top bar), then \"Preview Running Application\".</p> </li> <li> <p>Sign-up (remember, first signed up user get admin access), then go to User icon at top right, settings, admin settings, connections, then edit OpenAI API to be as follows:</p> <pre><code>http://litellm-service.default.svc.cluster.local:4000/v1\n</code></pre> <p>Click on \"Verify connection\" button to make sure connectivity is in-place, then save. You should be able to see three of the Bedrock models available in Open WebUI as depicted in the screenshot below:</p> <p></p> <p>Now, we have the admin user created, we can make Open WebUI accessible publicly.</p> </li> <li> <p>Update Open WebUI helm release to include <code>Ingress</code> object for exposing it:     <pre><code>envsubst &lt; bedrock-litellm/helm/open-webui-public-values.yaml | helm upgrade \\\n    open-webui open-webui/open-webui \\\n    --namespace open-webui \\\n    -f -\n</code></pre></p> </li> <li> <p>Extract Open WebUI URL:     <pre><code>kubectl -n open-webui get ingress open-webui  -o jsonpath='{.status.loadBalancer.ingress[*].hostname}'\n</code></pre></p> </li> <li> <p>Add a CNAME record for <code>&lt;open-webui-hostname&gt;</code> (check prerequisities section) that points to the ALB host name, then access Open WebUI using <code>&lt;open-webui-hostname&gt;</code>.</p> </li> </ol> <p>NOTE: ELB needs a minutes or so to complete the target registration; if the URL above did not work for you, wait for a few seconds for the registration to get completed.</p> <p>Edit <code>litellm/proxy_config.yaml</code>, update the IAM policy <code>litellm-bedrock-policy.json</code>, and enable access through the Bedrock console to add more Bedrock models on LiteLLM.</p>"},{"location":"50-clean-up/10-clean-up/","title":"Clean-up","text":"<ol> <li> <p>Uninstall Open WebUI: <pre><code>helm uninstall open-webui --namespace open-webui\n</code></pre></p> </li> <li> <p>Uninstall LiteLLM <pre><code>kubectl delete -f litellm/deploy/kubernetes/service.yaml\nkubectl delete -f litellm/deploy/kubernetes/kub.yaml\nkubectl delete configmap litellm-config\neksctl delete iamserviceaccount \\\n    --name litellm-sa \\\n    --cluster $CLUSTER_NAME\naws iam delete-policy --policy-arn $LITELLM_BEDROCK_IAM_POLICY_ARN\n</code></pre></p> </li> <li> <p>Uninstall AWS LBC <pre><code>helm uninstall aws-load-balancer-controller --namespace kube-system\neksctl delete iamserviceaccount \\\n    --name aws-load-balancer-controller \\\n    --namespace=kube-system \\\n    --cluster $CLUSTER_NAME\naws iam delete-policy --policy-arn $AWS_LBC_IAM_POLICY_ARN\n</code></pre></p> </li> <li> <p>Uninstall EBS driver <pre><code>helm uninstall aws-ebs-csi-driver \\\n    --namespace kube-system\neksctl delete iamserviceaccount \\\n    --name ebs-csi-controller-sa \\\n    --cluster $CLUSTER_NAME\n</code></pre></p> </li> <li> <p>Delete cluster <pre><code>eksctl delete cluster --name $CLUSTER_NAME\n</code></pre></p> </li> <li> <p>Delete the CNAME DNS records and the ACM certiciates used for LiteLLM and Open WebUI</p> </li> </ol>"}]}